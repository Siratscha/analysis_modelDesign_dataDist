{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modify csv files to follow a certain distribution and keep only relevant columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = <path to csv containing labels and demographic groups> \n",
    "pathologies_metadata = pd.read_csv(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total distributions of front X-Rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_ap_samples = pathologies_metadata.loc[pathologies_metadata['ViewPosition'].isin(['PA', 'AP'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_subjects_df = pa_ap_samples.loc[:, ['subject_id','study_id', 'gender', 'dicom_id','split','ViewPosition',\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Enlarged Cardiomediastinum',\n",
    "            'Fracture',\n",
    "            'Lung Lesion',\n",
    "            'Lung Opacity',\n",
    "            'No Finding',\n",
    "            'Pleural Effusion',\n",
    "            'Pleural Other',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Support Devices' \n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243149"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_subjects_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset of ['Edema','Cardiomegaly','Support Devices','Atelectasis','Pleural Effusion',  'Lung Opacity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_subset = labels\n",
    "\n",
    "label_subset = ['Edema','Cardiomegaly','Atelectasis','Lung Opacity','Pleural Effusion','Support Devices']\n",
    "#label_subset = ['Edema','Cardiomegaly','Atelectasis']\n",
    "#label_subset = ['Edema','Support Devices','Cardiomegaly']\n",
    "column_subset = ['subject_id','study_id', 'gender', 'dicom_id','split'] \n",
    "column_subset = column_subset + label_subset\n",
    "\n",
    "data_subset = count_subjects_df.loc[:,column_subset]\n",
    "test_validate = count_subjects_df.loc[count_subjects_df[\"split\"] != \"train\",column_subset]\n",
    "data_subset[label_subset] = data_subset[label_subset].applymap(lambda x: np.nan if x <= 0 else x)\n",
    "data_subset.dropna(subset=label_subset, how='all', inplace=True)\n",
    "data_subset[label_subset] = data_subset[label_subset].applymap(lambda x: 0 if np.isnan(x) else x)\n",
    "#data_subset.to_csv('total_AP_PA_ds.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df,labels, byGender):\n",
    "    # Initialize an empty dictionary to store the aggregation functions\n",
    "    aggregation_functions = {}\n",
    "\n",
    "    # Iterate over the columns and add them to the aggregation functions dictionary\n",
    "    for column in labels:\n",
    "        aggregation_functions[column] = 'sum'\n",
    "    if byGender:\n",
    "        # Perform the dynamic aggregation\n",
    "        result = df.groupby(['gender']).agg(aggregation_functions)\n",
    "    else:\n",
    "        result = pd.DataFrame(df.agg(aggregation_functions)).T\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_array = [1, 3, 5, 10, 20, 40] #,80,160,320,640,1280,2560,5120,10240\n",
    "data_subset[\"powerset\"] = data_subset.apply(lambda x: sum(val * x[col] for val, col in zip(ids_array, label_subset)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  4.,  5.,  6.,  8.,  9., 10., 11., 13., 14., 15., 16.,\n",
       "       18., 19., 20., 21., 23., 24., 25., 26., 28., 29., 30., 31., 33.,\n",
       "       34., 35., 36., 38., 39., 40., 41., 43., 44., 45., 46., 48., 49.,\n",
       "       50., 51., 53., 54., 55., 56., 58., 59., 60., 61., 63., 64., 65.,\n",
       "       66., 68., 69., 70., 71., 73., 74., 75., 76., 78., 79.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_subset['powerset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS_c from \n",
    "## \"A First Approach to Deal with Imbalance in Multi-label Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_samples(df, x, gender = None):\n",
    "    if gender is not None:\n",
    "        temp_df = df.iloc[np.random.choice(np.where(df['gender'] == gender)[0],size=x)]\n",
    "    else:\n",
    "        sampled_rows = random.choices(df.index.tolist(), k=x)\n",
    "        temp_df = df.loc[sampled_rows]\n",
    "         #temp_df = df.sample(n=x)\n",
    "    result_df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_ros(D, size_increasing):\n",
    "    increment =  int(len(D) * size_increasing)\n",
    "    print(\"Total samples to add: \",increment)\n",
    "    unique_values = np.unique(D['powerset'])\n",
    "    labelset_Bag = []\n",
    "    for value in unique_values:\n",
    "        powerset = D.loc[D['powerset'] ==value]\n",
    "        labelset_Bag.append((powerset,value))\n",
    "\n",
    "    meanSize = sum(D['powerset'].value_counts()) / len(unique_values)  \n",
    "    \n",
    "    minBag = []\n",
    "\n",
    "    for labelset,powerset in labelset_Bag:\n",
    "        if len(labelset) < meanSize:\n",
    "            minBag.append((labelset,powerset))\n",
    "            # if powerset greater meanSize drop this powerset and append it at the end, after\n",
    "            # its size has been increased\n",
    "            \n",
    "\n",
    "\n",
    "    meanIncrement = increment/len(minBag)\n",
    "    minBag.sort(key=lambda df: len(df), reverse=True)\n",
    "    total_samples_inc = 0\n",
    "    for i,(minSet,powerset) in enumerate(minBag):\n",
    "        #if total_samples_inc >= increment:\n",
    "        #    break\n",
    "        \n",
    "        incrementBag = int(min(abs(len(minSet)-meanSize),meanIncrement))\n",
    "        remainder = int(meanIncrement - incrementBag)\n",
    "        # distribute among Bags könnte meinen die meanReduction für die nachfolgenden Bags zu erhöhen;\n",
    "        # gleichverteilt auf die verbleibenden Klassen \n",
    "        # print(gender, \"- samples deleted: \", reductionBag)\n",
    "        total_samples_inc += incrementBag\n",
    "        #D = D.drop(D[D['powerset'] == powerset].index)\n",
    "        minSet = add_samples(minSet,incrementBag)\n",
    "        D = pd.concat([D, minSet])\n",
    "        \n",
    "        num_remaining_cl = ((len(minBag)-1)-i)\n",
    "        if num_remaining_cl > 0:\n",
    "            meanIncrement += remainder/num_remaining_cl\n",
    "    print(\"Total samples added:\", total_samples_inc)\n",
    "    return D\n",
    "lp_ros(data_subset, 0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS_g:\n",
    "## considering gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_ovs_num_samples_gender(dataset, size_increasing):\n",
    "    num_fem_samples = dataset.loc[dataset['gender'] == 'F'].value_counts().size\n",
    "\n",
    "    \n",
    "    # Determine the number of samples to increase\n",
    "    increasing_count = int((len(dataset) * size_increasing) - len(dataset))\n",
    "    \n",
    "    female_ratio = num_fem_samples / len(dataset)\n",
    "    \n",
    "    # Calculate the desired number of removed samples for each gender\n",
    "    male_increasing = int(increasing_count * female_ratio )\n",
    "    female_increasing = int(increasing_count * (1- female_ratio))\n",
    "    increments = {'M':male_increasing,'F':female_increasing}\n",
    "    return increments\n",
    "\n",
    "det_ovs_num_samples_gender(data_subset, 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_ros_gender(D, size_increasing):\n",
    "    increment =  det_ovs_num_samples_gender(D, size_increasing)\n",
    "    print(\"Total samples to add: Male -\", increment['M'],\", Female - \", increment['F'])\n",
    "    unique_values = np.unique(D['powerset'])\n",
    "    labelset_Bag = []\n",
    "    meanSize = {'M':0, 'F':0}\n",
    "    for gender in meanSize.keys():\n",
    "        value_counts = 0\n",
    "   \n",
    "        for value in unique_values:\n",
    "            powerset = D.loc[(D['powerset']==value) & (D['gender'] == gender)]\n",
    "            labelset_Bag.append((powerset,value,gender))\n",
    "            value_counts += powerset.value_counts().size\n",
    "\n",
    "\n",
    "        meanSize[gender] = (value_counts / len(unique_values))\n",
    "\n",
    "    mean_values = sum(meanSize.values()) / len(meanSize)\n",
    "    meanSize = {key: mean_values for key in meanSize}\n",
    "    \n",
    "    minBag = []\n",
    "    bag_count = {'M':0, 'F':0}\n",
    "\n",
    "    for labelset, powerset_value, gender in labelset_Bag:\n",
    "        gender_size = meanSize[gender] \n",
    "\n",
    "        if len(labelset) < gender_size:\n",
    "            minBag.append((labelset,powerset_value, gender))\n",
    "            bag_count[gender] += 1\n",
    "\n",
    "\n",
    "    mean_increment_per_gender = {\n",
    "        gender: increment[gender] / bag_count[gender] if bag_count[gender] != 0 else 0\n",
    "        for gender in bag_count.keys()\n",
    "    }\n",
    "\n",
    "    minBag = sorted(minBag, key=lambda tup: len(tup[0]), reverse=True)\n",
    "\n",
    "    total_samples_added = {'M':0, 'F':0}  \n",
    "    for i,(minSet,powerset_value,gender) in enumerate(minBag):\n",
    "        if bag_count['M'] ==3:\n",
    "            print(\"sth\")\n",
    "\n",
    "        gender_size = meanSize[gender] \n",
    "\n",
    "        incrementBag = int(min(abs(len(minSet)-gender_size),mean_increment_per_gender[gender]))\n",
    "        remainder = int(mean_increment_per_gender[gender] - incrementBag)\n",
    "        # distribute among Bags könnte meinen die meanReduction für die nachfolgenden Bags zu erhöhen;\n",
    "        # gleichverteilt auf die verbleibenden Klassen \n",
    "\n",
    "        total_samples_added[gender] += incrementBag\n",
    "\n",
    "        minSet = add_samples(minSet,incrementBag, gender)\n",
    "        D = pd.concat([D, minSet])\n",
    "        # calculate remaining classes for each gender\n",
    "        bag_count[gender]-=1 \n",
    "        if bag_count[gender] > 0:\n",
    "            mean_increment_per_gender[gender] += remainder/bag_count[gender]\n",
    "    print(\"Total samples added:\", total_samples_added)\n",
    "    return D\n",
    "lp_ros_gender(data_subset, 1.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUS_c: \n",
    "## From \"A First Approach to Deal with Imbalance in Multi-label Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_samples(df, x, gender = None):\n",
    "    if gender is not None:\n",
    "        samples = df[df['gender'] == gender].sample(n=x)\n",
    "    else:\n",
    "        samples = df.sample(n=x)\n",
    "  \n",
    "    df = df.drop(samples.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_rus(D, size_reduction):\n",
    "    samples_to_delete = int(len(D) * size_reduction)\n",
    "    print(\"Total samples to delete:\", samples_to_delete)\n",
    "    unique_values = np.unique(D['powerset'])\n",
    "    labelset_Bag = []\n",
    "    for value in unique_values:\n",
    "        powerset = D.loc[D['powerset'] ==value]\n",
    "        labelset_Bag.append((powerset,value))\n",
    "\n",
    "    meanSize = sum(D['powerset'].value_counts()) / len(unique_values)  \n",
    "    majBag = []\n",
    "    for labelset,powerset in labelset_Bag:\n",
    "        if len(labelset) > meanSize:\n",
    "            majBag.append(labelset)\n",
    "            # if powerset greater meanSize drop this powerset and append it at the end, after\n",
    "            # its size has been reduced\n",
    "            D = D.drop(D[D['powerset'] == powerset].index)\n",
    "    \n",
    "    meanReduction = samples_to_delete/len(majBag)\n",
    "    majBag.sort(key=lambda df: len(df))\n",
    "    total_samples_del = 0\n",
    "    for i,majSet in enumerate(majBag):\n",
    "        if total_samples_del >= samples_to_delete:\n",
    "            break\n",
    "        reductionBag = int(min(len(majSet)-meanSize,meanReduction))\n",
    "        remainder = meanReduction - reductionBag\n",
    "        # distribute among Bags könnte meinen die meanReduction für die nachfolgenden Bags zu erhöhen;\n",
    "        # gleichverteilt auf die verbleibenden Klassen \n",
    "        # print(\"samples deleted: \", reductionBag)\n",
    "        total_samples_del += reductionBag\n",
    "        majSet = delete_samples(majSet,reductionBag)\n",
    "        D = pd.concat([D, majSet])\n",
    "        num_remaining_cl = ((len(majBag)-1)-i)\n",
    "        if num_remaining_cl > 0:\n",
    "            meanReduction += remainder/num_remaining_cl\n",
    "    print(\"Total samples deleted:\", total_samples_del)\n",
    "    return D\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUS_g: considering gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority group is: M\n",
      "Number of occurrences: 84953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5603205487583682, 84953, 66662, 'M', 'F')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The `det_excess` function takes a dataset as input and calculates the excess ratio between the majority and minority groups in terms of gender.\n",
    "def det_excess(dataset):\n",
    "\n",
    "    group_counts = dataset['gender'].value_counts()\n",
    "    majority_group = group_counts.idxmax()\n",
    "    minority_group = group_counts.idxmin()\n",
    "    max_occurrences = group_counts[majority_group]\n",
    "    min_occurrences = group_counts[minority_group]\n",
    "    print(\"The majority group is:\", majority_group)\n",
    "    print(\"Number of occurrences:\", max_occurrences)\n",
    "\n",
    "    return max_occurrences,min_occurrences, majority_group, minority_group\n",
    "\n",
    "det_excess(data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority group is: M\n",
      "Number of occurrences: 84953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'M': 24307.0, 'F': 6016.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The `det_num_samples_group` function takes in a dataset and a size reduction value as parameters to define how many samples have to be deleted\n",
    "# It first calls the `det_excess` function to determine the current ratio of occurrences between two groups in the dataset, \n",
    "# as well as the maximum and minimum occurrences and the majority and minority groups.\n",
    "def det_num_samples_group(dataset, size_reduction):\n",
    "    max_occurrences,min_occurrences,majority_group,minority_group = det_excess(dataset)\n",
    "    \n",
    "    \n",
    "    # Determine the number of samples to remove\n",
    "    removal_count = int(len(dataset) * size_reduction)\n",
    "    difference = max_occurrences - min_occurrences\n",
    "    \n",
    "    max_removals = 0 \n",
    "    min_removals = 0\n",
    "    max_removals += difference \n",
    "    if removal_count > difference:\n",
    "        excess_difference = (removal_count - difference) / 2\n",
    "        max_removals += excess_difference \n",
    "        min_removals += excess_difference\n",
    "    \n",
    "    removals = {majority_group:max_removals,minority_group:min_removals}\n",
    "    return removals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority group is: M\n",
      "Number of occurrences: 84953\n",
      "Total samples to delete: Male - 24307.0 , Female -  6016.0\n",
      "Total samples deleted: 30321\n"
     ]
    }
   ],
   "source": [
    "def lp_rus_gender(D, size_reduction):\n",
    "    removals = det_num_samples_group(D, size_reduction) \n",
    "    print(\"Total samples to delete: Male -\", removals['M'],\", Female - \", removals['F'])\n",
    "    unique_values = np.unique(D['powerset'])\n",
    "    labelset_Bag = []\n",
    "    meanSize = {'M':0, 'F':0}\n",
    "    for gender in meanSize.keys():\n",
    "            value_counts = 0\n",
    "    \n",
    "            for value in unique_values:\n",
    "                powerset = D.loc[(D['powerset']==value) & (D['gender'] == gender)]\n",
    "                labelset_Bag.append((powerset,value,gender))\n",
    "                value_counts += powerset.value_counts().size\n",
    "\n",
    "\n",
    "            meanSize[gender] = (value_counts / len(unique_values))\n",
    "\n",
    "    mean_values = sum(meanSize.values()) / len(meanSize)\n",
    "    meanSize = {key: mean_values for key in meanSize}\n",
    "\n",
    "    \n",
    "    majBag = []\n",
    "    bag_count = {'M':0, 'F':0}\n",
    "\n",
    "    for labelset, powerset_value, gender in labelset_Bag:\n",
    "        gender_mean_size = meanSize[gender]\n",
    "\n",
    "        if len(labelset) > gender_mean_size:\n",
    "            majBag.append((labelset, gender))\n",
    "            bag_count[gender] += 1\n",
    "            # if powerset greater meanSize drop this powerset and append it at the end, after\n",
    "            # its size has been reduced\n",
    "            D = D.drop(D[(D['powerset'] == powerset_value) & (D['gender'] == gender)].index)\n",
    "\n",
    "    mean_reduction_per_gender = {\n",
    "        gender: removals[gender] / bag_count[gender] if bag_count[gender] != 0 else 0\n",
    "        for gender in bag_count.keys()\n",
    "    }\n",
    "\n",
    "    majBag.sort(key=lambda tup: len(tup[0]))\n",
    "\n",
    "    total_samples_del = 0\n",
    "    for i,(majSet,gender) in enumerate(majBag):\n",
    "        gender_mean_size = meanSize[gender]\n",
    "        reductionBag = int(min(len(majSet)-gender_mean_size,mean_reduction_per_gender[gender]))\n",
    "        remainder = mean_reduction_per_gender[gender] - reductionBag\n",
    "        # distribute among Bags könnte meinen die meanReduction für die nachfolgenden Bags zu erhöhen;\n",
    "        # gleichverteilt auf die verbleibenden Klassen \n",
    "\n",
    "        total_samples_del += reductionBag\n",
    "        majSet = delete_samples(majSet,reductionBag, gender)\n",
    "        D = pd.concat([D, majSet])\n",
    "        # calculate remaining classes for each gender\n",
    "        bag_count[gender]-=1 #((len(majBag)-1)-i)\n",
    "        if bag_count[gender] > 0:\n",
    "            mean_reduction_per_gender[gender] += remainder/bag_count[gender]\n",
    "    print(\"Total samples deleted:\", total_samples_del)\n",
    "    return D\n",
    "df_lp_rus_gender = lp_rus_gender(data_subset, 0.2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority group is: M\n",
      "Number of occurrences: 82817\n",
      "Total samples to delete: Male - 31104.5 , Female -  13219.5\n",
      "Total samples deleted: 44323\n"
     ]
    }
   ],
   "source": [
    "percentage = 0.3\n",
    "training_data = data_subset.loc[data_subset[\"split\"] == \"train\"]\n",
    "test_vaildate = data_subset.loc[data_subset[\"split\"] != \"train\"]\n",
    "df_lp_rus_gender = lp_rus_gender(training_data, percentage)   \n",
    "\n",
    "df_lp_rus_gender = pd.concat([df_lp_rus_gender, test_vaildate], ignore_index=True)\n",
    "\n",
    "df_lp_rus_gender = df_lp_rus_gender.drop(['powerset'],axis=1)\n",
    "\n",
    "file_name = \"RUS/rus_gender\" + str(percentage).replace(\".\",\"\")+\".csv\"\n",
    "\n",
    "df_lp_rus_gender.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples to add: Male - 6492 , Female -  8281\n",
      "sth\n",
      "sth\n",
      "Total samples added: {'M': 6468, 'F': 8268}\n"
     ]
    }
   ],
   "source": [
    "percentage = 1.1\n",
    "training_data = data_subset.loc[data_subset[\"split\"] == \"train\"]\n",
    "test_vaildate = data_subset.loc[data_subset[\"split\"] != \"train\"]\n",
    "df_lp_ros_gender = lp_ros_gender(training_data, percentage)   \n",
    "\n",
    "df_lp_ros_gender = pd.concat([df_lp_ros_gender, test_vaildate], ignore_index=True)\n",
    "\n",
    "df_lp_ros_gender = df_lp_ros_gender.drop(['powerset'],axis=1)\n",
    "\n",
    "file_name = \"ROS/ros_gender\" + str(percentage).replace(\".\",\"\")+\".csv\"\n",
    "\n",
    "df_lp_ros_gender.to_csv(file_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
